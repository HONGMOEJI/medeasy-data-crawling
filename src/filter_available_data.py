import json
import aiohttp
import asyncio
import os
import time
import random
from datetime import datetime
from tqdm import tqdm  # í”„ë¡œê·¸ë ˆìŠ¤ ë°”
from bs4 import BeautifulSoup  # HTML íŒŒì‹±

# ğŸ“Œ íŒŒì¼ ê²½ë¡œ ì„¤ì •
DATA_DIR = "data"
PROCESSED_DIR = os.path.join(DATA_DIR, "processed")
RAW_DIR = os.path.join(DATA_DIR, "raw")
FILTERED_DIR = os.path.join(DATA_DIR, "filtered")
LOGS_DIR = os.path.join(DATA_DIR, "logs")  # ë¡œê·¸ ë””ë ‰í† ë¦¬ ì¶”ê°€

DRUG_FILE = os.path.join(PROCESSED_DIR, "drug_approval_data_processed.json")
PILL_FILE = os.path.join(RAW_DIR, "pill_raw_data.json")

FILTERED_DRUG_FILE = os.path.join(FILTERED_DIR, "filtered_drug_approvals.json")
FILTERED_PILL_FILE = os.path.join(FILTERED_DIR, "filtered_pill_data.json")

# ğŸ“Œ í•„ìš”í•œ ë””ë ‰í† ë¦¬ ìƒì„±
for directory in [FILTERED_DIR, LOGS_DIR]:
    os.makedirs(directory, exist_ok=True)

# ğŸ“Œ ë¡œê¹… ì„¤ì •
def setup_logger():
    """ë¡œê¹… ì„¤ì • ë° ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_file = os.path.join(LOGS_DIR, f"filter_process_{timestamp}.log")
    
    with open(log_file, "w", encoding="utf-8") as f:
        f.write(f"=== í•„í„°ë§ í”„ë¡œì„¸ìŠ¤ ë¡œê·¸ ({timestamp}) ===\n\n")
    
    print(f"ğŸ“ ë¡œê·¸ íŒŒì¼ ìƒì„±: {log_file}")
    return log_file

def log_message(message, log_file, print_to_console=True):
    """ë¡œê·¸ ë©”ì‹œì§€ ê¸°ë¡"""
    timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    log_entry = f"[{timestamp}] {message}"
    
    if print_to_console:
        print(log_entry)
    
    with open(log_file, "a", encoding="utf-8") as f:
        f.write(log_entry + "\n")

# âœ… 1. JSONì—ì„œ ë°ì´í„° ë¡œë“œ (+ ìƒ˜í”Œ ê¸°ëŠ¥)
def load_json(file_path, log_file, sample_size=None):
    """JSON íŒŒì¼ ë¡œë“œ ë° ìƒ˜í”Œë§"""
    log_message(f"ğŸ“‚ JSON íŒŒì¼ ë¡œë“œ ì¤‘: {file_path}", log_file)
    
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            data = json.load(f)
        
        if sample_size and len(data) > sample_size:
            data = random.sample(data, sample_size)
            log_message(f"ğŸ” ìƒ˜í”Œë§ ì ìš©: {sample_size}ê°œ ë°ì´í„° ì„ íƒë¨", log_file)
        
        log_message(f"ğŸ”¢ ì´ {len(data)}ê°œì˜ í•­ëª© ë¡œë“œ ì™„ë£Œ", log_file)
        return data
    except Exception as e:
        log_message(f"âŒ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}", log_file)
        return []

# âœ… 2. ë¹„ë™ê¸° ìš”ì²­ í•¨ìˆ˜ (í•„í„°ë§ ê¸°ì¤€ ê°œì„ )
async def fetch_status(session, item, log_file, request_index=None, total_requests=None):
    """ì‹ì•½ì²˜ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ITEM_SEQ ë“±ë¡ ì—¬ë¶€ë¥¼ í™•ì¸í•˜ëŠ” ë¹„ë™ê¸° í•¨ìˆ˜"""
    item_seq = item.get("ITEM_SEQ")
    if not item_seq:
        log_message(f"âš ï¸ ITEM_SEQ ì—†ìŒ, ê±´ë„ˆëœ€", log_file, False)
        return item, False, "ITEM_SEQ_MISSING"
    
    url = f"https://nedrug.mfds.go.kr/searchDrug?searchYn=true&itemSeq={item_seq}"
    headers = {"User-Agent": "Mozilla/5.0"}

    progress_info = f"[{request_index}/{total_requests}]" if request_index and total_requests else ""
    item_name = item.get("ITEM_NAME", "ì´ë¦„ ì—†ìŒ")
    log_message(f"ğŸ” {progress_info} í™•ì¸ ì¤‘: {item_name} (ITEM_SEQ: {item_seq})", log_file, False)
    
    try:
        async with session.get(url, headers=headers, timeout=10) as response:
            html = await response.text()
            soup = BeautifulSoup(html, "html.parser")

            # âŒ "ì¡°íšŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤." â†’ ë¬´ì¡°ê±´ ë¯¸ë“±ë¡
            if soup.find("span", string="ì¡°íšŒ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."):
                log_message(f"âŒ {progress_info} ë¯¸ë“±ë¡: {item_name} (ITEM_SEQ: {item_seq})", log_file, False)
                return item, False, "NOT_REGISTERED"

            # âœ… ë“±ë¡ëœ ê²½ìš°: <table> ë‚´ë¶€ì— `getItemDetail?itemSeq=` í¬í•¨ ì—¬ë¶€ í™•ì¸
            result_table = soup.find("table", class_="dr_table2")
            if result_table and result_table.find("a", href=lambda x: x and "getItemDetail?itemSeq=" in x):
                log_message(f"âœ… {progress_info} ë“±ë¡ë¨: {item_name} (ITEM_SEQ: {item_seq})", log_file, False)
                return item, True, "REGISTERED"

            log_message(f"âš ï¸ {progress_info} ì˜ˆì™¸ ìƒí™© ë°œìƒ (ì •í™•í•œ ë“±ë¡ ì—¬ë¶€ í™•ì¸ ë¶ˆê°€)", log_file, False)
            return item, False, "UNKNOWN_RESPONSE"
    
    except Exception as e:
        log_message(f"âš ï¸ {progress_info} ìš”ì²­ ì˜¤ë¥˜ ë°œìƒ: {str(e)} (ITEM_SEQ: {item_seq})", log_file, False)
        return item, False, f"ERROR: {str(e)}"

# âœ… 3. ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ë°ì´í„° í•„í„°ë§
async def filter_data_async(data, batch_size=10, log_file=None):
    """ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ë°ì´í„° í•„í„°ë§"""
    valid_data = []
    total_items = len(data)
    
    log_message(f"ğŸš€ ì´ {total_items}ê°œ í•­ëª© í•„í„°ë§ ì‹œì‘ (ë°°ì¹˜ í¬ê¸°: {batch_size})", log_file)
    pbar = tqdm(total=total_items, desc="í•„í„°ë§ ì§„í–‰ ì¤‘")

    async with aiohttp.ClientSession() as session:
        tasks = []
        for idx, item in enumerate(data):
            request_index = idx + 1
            tasks.append(fetch_status(session, item, log_file, request_index, total_items))
            
            if len(tasks) >= batch_size:
                results = await asyncio.gather(*tasks)
                valid_data.extend([item for item, is_valid, _ in results if is_valid])
                tasks = []
                pbar.update(batch_size)

        if tasks:
            results = await asyncio.gather(*tasks)
            valid_data.extend([item for item, is_valid, _ in results if is_valid])
            pbar.update(len(tasks))

    pbar.close()
    log_message(f"âœ… í•„í„°ë§ ì™„ë£Œ! ë“±ë¡ëœ í•­ëª© ìˆ˜: {len(valid_data)}/{total_items}", log_file)
    return valid_data

# âœ… 4. ì‹¤í–‰ (ìƒ˜í”Œë§ ì ìš© ê°€ëŠ¥)
async def main(sample_size=None):
    log_file = setup_logger()
    start_time = time.time()

    log_message("ğŸš€ ë°ì´í„° í•„í„°ë§ í”„ë¡œì„¸ìŠ¤ ì‹œì‘", log_file)

    log_message("\nğŸ” í—ˆê°€ì •ë³´ ë°ì´í„° í•„í„°ë§ ì‹œì‘...", log_file)
    drug_data = load_json(DRUG_FILE, log_file, sample_size)
    filtered_drug_data = await filter_data_async(drug_data, batch_size=10, log_file=log_file)
    with open(FILTERED_DRUG_FILE, "w", encoding="utf-8") as f:
        json.dump(filtered_drug_data, f, ensure_ascii=False, indent=4)

    log_message("\nğŸ” ë‚±ì•Œì •ë³´ ë°ì´í„° í•„í„°ë§ ì‹œì‘...", log_file)
    pill_data = load_json(PILL_FILE, log_file, sample_size)
    filtered_pill_data = await filter_data_async(pill_data, batch_size=15, log_file=log_file)
    with open(FILTERED_PILL_FILE, "w", encoding="utf-8") as f:
        json.dump(filtered_pill_data, f, ensure_ascii=False, indent=4)

    log_message("âœ… ì „ì²´ í•„í„°ë§ ì™„ë£Œ!", log_file)

# ë¹„ë™ê¸° ì‹¤í–‰ (ìƒ˜í”Œ ê°œìˆ˜ ì§€ì • ê°€ëŠ¥)
if __name__ == "__main__":
    asyncio.run(main(sample_size=None))  # ìƒ˜í”Œë§ ì ìš© ì‹œ: sample_size=100
